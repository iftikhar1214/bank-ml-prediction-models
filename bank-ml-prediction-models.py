# -*- coding: utf-8 -*-
"""banking dataset task 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19cYH8AVCx5Kj908a4_UiBqZCfau4dltV
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.svm import SVC

# Load the dataset
df = pd.read_csv("/content/drive/MyDrive/internship/dataset/bank-additional-full.csv", sep=';')

# Encode categorical variables
df_encoded = df.copy()
le = LabelEncoder()
for col in df_encoded.select_dtypes(include='object').columns:
    df_encoded[col] = le.fit_transform(df_encoded[col])

# Split features and target
X = df_encoded.drop("y", axis=1)
y = df_encoded["y"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Drop 'duration' as it's a data leak (strong predictor added after contact)
df.drop('duration', axis=1, inplace=True)

# Encode categorical columns
label_enc = LabelEncoder()
for col in df.select_dtypes(include='object').columns:
    df[col] = label_enc.fit_transform(df[col])

# Split into features and target
X = df.drop("y", axis=1)
y = df["y"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# Load data (keep duration)
df = pd.read_csv("C:/Users/Naib Toorie/Downloads/bank-additional-full.csv", sep=';')

# One-hot encode
df_encoded = pd.get_dummies(df, drop_first=True)

# Export to CSV
df_encoded.to_csv("C:/Users/Naib Toorie/Downloads/bank_cleaned.csv", index=False)

# Linear Kernel
linear_svm = SVC(kernel='linear')
linear_svm.fit(X_train, y_train)
y_pred_linear = linear_svm.predict(X_test)

# Evaluation
print("ðŸ”¹ Linear SVM Results")
print("Accuracy:", accuracy_score(y_test, y_pred_linear))
print(classification_report(y_test, y_pred_linear))

# Polynomial Kernel
poly_svm = SVC(kernel='poly', degree=3)
poly_svm.fit(X_train, y_train)
y_pred_poly = poly_svm.predict(X_test)

# Evaluation
print("ðŸ”¹ Polynomial SVM Results")
print("Accuracy:", accuracy_score(y_test, y_pred_poly))
print(classification_report(y_test, y_pred_poly))

# RBF Kernel
rbf_svm = SVC(kernel='rbf')
rbf_svm.fit(X_train, y_train)
y_pred_rbf = rbf_svm.predict(X_test)

# Evaluation
print("ðŸ”¹ RBF SVM Results")
print("Accuracy:", accuracy_score(y_test, y_pred_rbf))
print(classification_report(y_test, y_pred_rbf))



import matplotlib.pyplot as plt
import seaborn as sns

accuracies = {
    'Linear': accuracy_score(y_test, y_pred_linear),
    'Polynomial': accuracy_score(y_test, y_pred_poly),
    'RBF': accuracy_score(y_test, y_pred_rbf)
}

plt.figure(figsize=(8, 5))
sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette='viridis')
plt.title("SVM Kernel Accuracy Comparison")
plt.ylabel("Accuracy")
for i, v in enumerate(accuracies.values()):
    plt.text(i, v + 0.005, f"{v:.3f}", ha='center')
plt.ylim(0.8, 1.0)
plt.tight_layout()
plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

log_model = LogisticRegression(max_iter=1000)
log_model.fit(X_train, y_train)
y_pred_log = log_model.predict(X_test)

print("ðŸ”¹ Logistic Regression")
print("Accuracy:", accuracy_score(y_test, y_pred_log))
print(classification_report(y_test, y_pred_log))

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

print("ðŸ”¹ Random Forest")
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

accuracies = {
    "Logistic Regression": accuracy_score(y_test, y_pred_log),
    "Random Forest": accuracy_score(y_test, y_pred_rf)
}

plt.figure(figsize=(8, 5))
sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette='coolwarm')
plt.title("Accuracy: Logistic Regression vs Random Forest")
plt.ylabel("Accuracy")
for i, v in enumerate(accuracies.values()):
    plt.text(i, v + 0.005, f"{v:.3f}", ha='center')
plt.ylim(0.8, 1.0)
plt.tight_layout()
plt.show()